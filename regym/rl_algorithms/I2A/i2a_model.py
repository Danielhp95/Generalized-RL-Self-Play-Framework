import torch
import torch.nn as nn
from regym.rl_algorithms.I2A import ImaginationCore


class I2AModel(nn.Module):
    '''
    Refer to Figure 1 of original paper: https://arxiv.org/pdf/1707.06203.pdf
    for a visual representation of this model. The basic functionality of this
    model is to act as a policy network. It recieves a state / observation from
    the environment and returns (amongs other things) an action to be executed.
    '''
    def __init__(self, actor_critic_head: nn.Module,
                 model_free_network: nn.Module,
                 aggregator,
                 rollout_encoder: nn.Module,
                 imagination_core: ImaginationCore,
                 imagined_rollouts_per_step: int,
                 rollout_length: int,
                 use_cuda: bool):
        '''
        :param actor_critic_head: nn.Module: Head of the model which outputs a
                                  distribution over actions and an estimation
                                  of the value of the state / observation. It
                                  receives as input the concatenation of:
                                      - The output of :param aggregator:
                                      - The output of :param model_free_network:
        :param model_free_network: nn.Module: Body of the module which takes
                                   a state / observation of the environment
                                   as input and outputs a feature vector
                                   to be used by the :param actor_critic_head:
        :param aggregator: Aggregator function which processes all rollout encodings
                           created by :param rollout_encoder:. The output of the
                           aggregator will be concatenated with the output of
                           :param model_free_network: to be passed as input
                           to :param actor_critic_head:
        :param rollout_encoder: nn.MModule: Recurrent Neural Net which takes
                                as input the trajectories generated by the
                                :param imagination_core: and individually encodes
                                each one into an `rollout embedding` which will
                                be passed as input to the :param aggregator:
        :param imagination_core: ImaginationCore: object containing a distill policy
                                 and an environment model which in conjunction are
                                 used to generate `imaginary` trajectories by using
                                 the distill policy and environment model to do
                                 forward planning.
        :param imagined_rollouts_per_step: int. Number of rollouts to generate
                                           through the :param imagination_core:
                                           for every forward pass of this model
        :param rollout_length: Number of steps to take on each forward rollout
                               by the :param imagination_core:
        :param use_cuda: Bool: Whether or not to use CUDA for this model's computation
        '''
        super(I2AModel, self).__init__()

        self.actor_critic_head = actor_critic_head
        self.model_free_network = model_free_network
        self.aggregator = aggregator
        self.rollout_encoder = rollout_encoder
        self.imagination_core = imagination_core
        self.imagined_rollouts_per_step = imagined_rollouts_per_step
        self.rollout_length = rollout_length
        self.use_cuda = use_cuda

        if use_cuda: self = self.cuda()

    def forward(self, state: torch.Tensor, action=None):
        '''
        :param state: torch.Tensor: preprocessed observation/state as a PyTorch Tensor
                      of dimensions batch_size=1 x input_shape
        :param action: action for which the log likelyhood will be computed.
        :returns: the prediction dictionary returned from the
                  :self.actor_critic_head.__forward__(): method
        '''
        rollout_embeddings = []
        for i in range(self.imagined_rollouts_per_step):
            # 1. Imagine state and reward for self.imagined_rollouts_per_step times
            rollout_states, rollout_rewards = self.imagination_core.imagine_rollout(state, self.rollout_length)
            # dimensions: self.rollout_length x batch x input_shape / reward-size
            # 2. encode them with RolloutEncoder and use aggregator to concatenate them together into imagination code
            rollout_embedding = self.rollout_encoder(rollout_states, rollout_rewards)
            # dimensions: batch x rollout_encoder_embedding_size
            rollout_embeddings.append(rollout_embedding.unsqueeze(1))
        rollout_embeddings = torch.cat(rollout_embeddings, dim=1)
        # dimensions: batch x self.imagined_rollouts_per_step x rollout_encoder_embedding_size
        imagination_code = self.aggregator(rollout_embeddings)
        # dimensions: batch x self.imagined_rollouts_per_step*rollout_encoder_embedding_size
        # 3. model free pass
        features = self.model_free_network(state)
        # dimensions: batch x model_free_feature_dim
        # 4. concatenate model free pass and imagination code
        imagination_code_features = torch.cat([imagination_code, features], dim=1)
        # 5. Final fully connected layer which turns into action.
        prediction = self.actor_critic_head(imagination_code_features, action=action)
        return prediction
